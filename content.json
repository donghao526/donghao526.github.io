{"pages":[],"posts":[{"title":"母亲节","text":"好文共赏揭秘！现代IM系统的消息架构如何设计？。之前的IM系统都做的很简单，推拉很难平衡，文中提供了一个新的思路。一个技术人，如何做到比别人更突出。1.做出承诺，超出预期;2.重要不紧急的事如何决定函数的抽象层级https://my.oschina.net/jamesview/blog/2994112","link":"/2019/05/13/mothersday/"},{"title":"Nginx日志切分","text":"最近还是有点累，睡了一天感觉还是略困，这周太忙了，但是很多时候忙到最后，却发现得大于失。感谢周围的同事给我提出的一些建议，还有劝勉，能使我得到些许慰借。为什么想写日志切分，因为一直我好像没有研究过它如何实现，至于如何实现，的确也有多种方法，先写nginx官方推荐的吧。 Nginx官方推荐的日志切分方式 Log Rotation:官方推荐的日志切分实现 1234$ mv access.log access.log.0$ kill -USR1 `cat master.nginx.pid`$ sleep 1$ gzip access.log.0 # do something with access.log.0 原理如下： 将access.log重命名为access.log.0，由于linux都采取文件描述符来读取文件，因此重命名文件后日志还是会持续的向原文件写入 USER1是linux中自定义的信号机制，意思就是说我们可以自己在开发中收到该信号时决定来做什么，nginx在收到该信号时会重新读取配置文件 sleep 1秒能确保nginx将之前的旧日志文件能够彻底的关闭 具体实现设想如果要定时的切分日志，那需要一个定时任务，来定时的对日志文件重命名并且引导nginx写入新的文件，而另一个shell脚本用来做具体的日志切割实现 定时任务如何实现定时任务，有多种多样的solution，为了简单，我就使用mac上的crontab吧， crontab -e添加一行 1*/1 * * * * sh ~/logrotation.sh #每一分钟切割一次日志 日志切割脚本12345#! /bin/shtime=`date +%Y%m%d%H%m`mv access.log access.log.$&#123;time&#125;kill -USR1 `ps -ef | grep nginx | grep master |awk &apos;&#123;print $2&#125;&apos;` ## 获取nginx的pid，没找到pid文件，就偷懒了sleep 1 执行结果12baidudeMacBook-Pro:log echo$ lsaccess.log access.log.201709172136 access.log.201709172137 如上图所示，日志切分成功。 扩展阅读5个使用Redis时需要注意的事项：对于Redis的使用和建议改了一些比较中肯的建议，很实用。","link":"/2018/03/28/nginx日志切分/"},{"title":"十年","text":"无意中得知新浪博客已经写了10年了，确实互联网生活改变了太多，前几日，去了趟江南，感触颇多。 千万不要在小长假出行，人实在太多，看来灭霸是有些道理的 江南还是生活环境更好，人们思维和观念也比北方人更新颖一些，多和南方人交流 北上广深，活着实在太累，陆家嘴的繁华和我半毛钱关系没有 gcc -l竟然是链接动态库，哈哈，一直以为是静态","link":"/2019/05/05/shinian/"},{"title":"个人计划","text":"不知道到这个时候还算不算晚，已经Q2了，但还是想做一些计划. 工作换一个挑战性的工作，早点摆脱现在这种浑浑噩噩的日子。 健康减肥到60斤 财富扣除结婚经费，可以买一辆亚洲龙","link":"/2019/04/16/个人计划/"},{"title":"布隆过滤器","text":"布隆过滤器一种空间数据结构，用来判断一个元素是否在某个集合中。由于具有假阳性，所以布隆过滤器只能得出某个元素有可能在该集合，反之该元素一定不在这个集合中。 布隆过滤器简介一个空的布隆过滤器是一个m位均为0的比特位数组，同时定义了k个哈希函数，将某个元素得出的哈希值映射到m个比特位中的某一位，将该为置为1，生成一个随机的分布。通常k要远远小于m，k和m的选取取决于过滤器的假阳性概率。 添加元素当给布隆过滤器中添加一个元素时，利用k个哈希函数得出k个位置，并将$m$个比特位中对应的k个位置设置为1。 查询元素查询元素时同样计算出k个位置，并获取该$k$个位置的所有元素值，当有一个位为0的话，就证明该元素不在该集合里。若k个位置均为1，则表示该元素可能在集合里，因为某些为1的位可能是别的元素在插入时设置的。 删除元素由于假阳性的引入，布隆过滤器是不能删除元素的。 布隆过滤器的优点链表、哈希表和平衡二叉树都能够做元素的查找，但是布隆过滤器明显在时间和空间利用率上更优 空间利用率一个拥有1%的错误率和一个优化后的$k$的布隆过滤器，存储一个元素只需要9.6bit，没降低1%的错误率每个元素也只需增加4.8bit [文章中写的结论，还需要看证明过程] 时间复杂度时间复杂度显然是$O(k)$ 假阳性的概率假定一个哈希函数选择每个插入位置的概率都是相等的，且位数组一共m位，那么某个比特位被hash函数设为1的概率为$$ 1 - \\frac{1}{m}$$那么通过计算k个哈希函数后，该位被置为1的概率为$$ ( 1 - \\frac{1}{m} )^k$$如果该过滤器有n个元素，那么该位为0的概率为$$ ( 1 - \\frac{1}{m} )^{kn}$$该位为1的概率为$$ 1- ( 1 - \\frac{1}{m} )^kn$$那么随便找k个位置，这些位置都为1的概率(也可认为是假阳性概率)为$$ (1- ( 1 - \\frac{1}{m} )^{kn})^k \\approx (1 - e^{-kn/m})^k$$需要注意的是，该概率不是严格准确的，因为$k$个为在被置1时，不是独立事件，但是概率大约是相似的。由此可见，假阳性的概率随着比特位数组长度$m$的增大而减小，随着集合元素$n的增大而增大。那么证明了如果$m$足够大，布隆过滤器的准确性还是很高的。 如何寻找最适合的k最适合的$k$就是能够使过滤器假阳性的概率达到最低，直观来讲增加哈希函数可以提升准确率，但是又会影响更多的比特位，所以随着哈希函数数量k的增加，假阳性概率或许增加或许减少，因此怎么算最适合的k呢。我们拿出上述得到的概率，假定假阳性概率为f $$ f = (1 - e^{-kn/m})^k$$为了简化运算对$f$取对数$$ g = ln(f) = k(1 - e^{-kn/m})$$对其进行求导$$\\frac{dg}{dk} = ln(1 - e^{-kn/m}) + \\frac{kn}{m} \\frac{e^{-kn/m}}{1 - e^{-kn/m}}$$当导数为0的时候，就是最适合的k，我们得出最适合的k如下:$$ k = \\frac{m}{n}ln(2) $$ 元素数量估算Swamidass &amp; Baldi提出了布隆过滤器中实际元素估算的方式$$ n^* = - \\frac{m}{k} ln [1-\\frac{X}{k}] $$ 其中，$$ n$*为元素个数的近似值，m是位数组长度，k是哈希函数的数量, $X$是位数组中被置为1的位的数量。还没有看完证明过程 总结布隆过滤器由于引入了假阳性，因此不太适合高精度的需求，业务场景需要能够接受一定错误容忍度，但是查询和插入都是$O(k)$的时间复杂度，空间复杂度也相当可观，因此在快速的元素查找定位场景还是大有裨益的。 参考文献Bloom_filterNotes 10 for CS 170Mathematical Correction for Fingerprint Similarity Measures to Improve Chemical Retrieval","link":"/2019/03/28/布隆过滤器/"},{"title":"走出舒适区","text":"说来惭愧，上一次更新已经三个月了，这三个月发生了很多，但自己始终没有成长，加油，make change！","link":"/2019/08/22/走出舒适区/"}],"tags":[{"name":"life","slug":"life","link":"/tags/life/"},{"name":"nginx","slug":"nginx","link":"/tags/nginx/"},{"name":"生活","slug":"生活","link":"/tags/生活/"}],"categories":[]}