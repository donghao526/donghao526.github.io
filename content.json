{"pages":[],"posts":[{"title":"Nginx日志切分","text":"为什么想写日志切分，因为一直我好像没有研究过它如何实现，至于如何实现，的确也有多种方法，先写nginx官方推荐的吧。 Nginx官方推荐的日志切分方式 Log Rotation:官方推荐的日志切分实现 1234$ mv access.log access.log.0$ kill -USR1 `cat master.nginx.pid`$ sleep 1$ gzip access.log.0 # do something with access.log.0 原理如下： 将access.log重命名为access.log.0，由于linux都采取文件描述符来读取文件，因此重命名文件后日志还将持续的向原文件写入 USER1是linux中自定义的信号机制，nginx在收到该信号时会重新读取配置文件 sleep 1秒能确保nginx将之前的旧日志文件能够彻底的关闭 具体实现 设想如果要定时的切分日志，那需要一个定时任务，来定时的对日志文件重命名并且引导nginx写入新的文件，而另一个shell脚本用来做具体的日志切割实现 定时任务如何实现定时任务，有多种多样的solution，为了简单，我就使用mac上的crontab吧， crontab -e添加一行 12#每一分钟切割一次日志 */1 * * * * sh ~/logrotation.sh 日志切割脚本1234567#! /bin/shtime=`date +%Y%m%d%H%m`mv access.log access.log.${time}## 获取nginx的pid，没找到pid文件，就偷懒了kill -USR1 `ps -ef | grep nginx | grep master |awk &apos;{print $2}&apos;`sleep 1 执行结果12baidudeMacBook-Pro:log echo$ lsaccess.log access.log.201709172136 access.log.201709172137 如上图所示，日志切分成功。 扩展阅读5个使用Redis时需要注意的事项：对于Redis的使用和建议改了一些比较中肯的建议，很实用。","link":"/2018/03/28/001-nginx日志切分/"},{"title":"布隆过滤器","text":"布隆过滤器一种空间数据结构，用来判断一个元素是否在某个集合中。由于具有假阳性，所以布隆过滤器只能得出某个元素有可能在该集合，反之该元素一定不在这个集合中。 布隆过滤器简介一个空的布隆过滤器是一个\\(m\\)位均为\\(0\\)的比特位数组，同时定义了\\(k\\)个哈希函数，将某个元素得出的哈希值映射到m个比特位中的某一位，将该为置为1，生成一个随机的分布。通常\\(k\\)要远远小于\\(m\\)，\\(k\\)和\\(m\\)的选取取决于过滤器的假阳性概率。 添加元素当给布隆过滤器中添加一个元素时，利用\\(k\\)个哈希函数得出\\(k\\)个位置，并将\\(m\\)个比特位中对应的\\(k\\)个位置设置为\\(1\\)。 查询元素查询元素时同样计算出\\(k\\)个位置，并获取该\\(k\\)个位置的所有元素值，当有一个位为\\(0\\)的话，就证明该元素不在该集合里。若\\(k\\)个位置均为\\(1\\)，则表示该元素可能在集合里，因为某些为\\(1\\)的位可能是别的元素在插入时设置的。 删除元素由于假阳性的引入，布隆过滤器是不能删除元素的。 布隆过滤器的优点链表、哈希表和平衡二叉树都能够做元素的查找，但是布隆过滤器明显在时间和空间利用率上更优 空间利用率一个拥有1%的错误率和一个优化后的\\(k\\)的布隆过滤器，存储一个元素只需要\\(9.6\\)bit，没降低\\(1%\\)的错误率每个元素也只需增加\\(4.8\\)bit [文章中写的结论，还需要看证明过程] 时间复杂度时间复杂度显然是\\(O(k)\\) 假阳性的概率假定一个哈希函数选择每个插入位置的概率都是相等的，且位数组一共\\(m\\)位，那么某个比特位被hash函数不设为1的概率为$$ 1 - \\frac{1}{m}$$那么通过计算k个哈希函数后，该位不被置为1的概率为$$ ( 1 - \\frac{1}{m} )^k$$如果该过滤器有n个元素，那么该位为0的概率为$$ ( 1 - \\frac{1}{m} )^{kn}$$该位为1的概率为$$ 1- ( 1 - \\frac{1}{m} )^{kn}$$那么随便找k个位置，这些位置都为1的概率(也可认为是假阳性概率)为$$ (1- ( 1 - \\frac{1}{m} )^{kn})^k \\approx (1 - e^{-kn/m})^k$$需要注意的是，该概率不是严格准确的，因为\\(k\\)个为在被置1时，不是独立事件，但是概率大约是相似的。由此可见，假阳性的概率随着比特位数组长度\\(m\\)的增大而减小，随着集合元素\\(n\\)的增大而增大。那么证明了如果\\(m\\)足够大，布隆过滤器的准确性还是很高的。 如何寻找最适合的k最适合的\\(k\\)就是能够使过滤器假阳性的概率达到最低，直观来讲增加哈希函数可以提升准确率，但是又会影响更多的比特位，所以随着哈希函数数量k的增加，假阳性概率或许增加或许减少，因此怎么算最适合的k呢。我们拿出上述得到的概率，假定假阳性概率为\\(f\\) $$ f = (1 - e^{-kn/m})^k$$为了简化运算对$f$取对数$$ g = ln(f) = k*ln(1 - e^{-kn/m})$$对其进行求导$$\\frac{dg}{dk} = ln(1 - e^{-kn/m}) + \\frac{kn}{m} \\frac{e^{-kn/m}}{1 - e^{-kn/m}}$$当导数为0的时候，就是最适合的k，我们得出最适合的k如下:$$ k = \\frac{m}{n}ln(2) $$ 元素数量估算Swamidass &amp; Baldi提出了布隆过滤器中实际元素估算的方式$$ n^* = - \\frac{mln[1-\\frac{X}{k}]}{m} $$ 其中，\\(n^*\\)为元素个数的近似值，\\(m\\)是位数组长度，\\(k\\)是哈希函数的数量, \\(X\\)是位数组中被置为1的位的数量。还没有看完证明过程 总结布隆过滤器由于引入了假阳性，因此不太适合高精度的需求，业务场景需要能够接受一定错误容忍度，但是查询和插入都是\\(O(k)\\)的时间复杂度，空间复杂度也相当可观，因此在快速的元素查找定位场景还是大有裨益的。 参考文献Bloom_filterNotes 10 for CS 170Mathematical Correction for Fingerprint Similarity Measures to Improve Chemical Retrieval","link":"/2020/09/08/002-布隆过滤器/"},{"title":"小长假","text":"千万不要在小长假出行，人实在太多，看来灭霸是有些道理的","link":"/2019/05/05/003-小长假/"},{"title":"好文共赏","text":"揭秘！现代IM系统的消息架构如何设计？。之前的IM系统都做的很简单，推拉很难平衡，文中提供了一个新的思路。 一个技术人，如何做到比别人更突出。 如何决定函数的抽象层级https://my.oschina.net/jamesview/blog/2994112","link":"/2019/05/13/004-好文共赏/"},{"title":"坚持就会更加坚定","text":"距离泰山马拉松结束已经两周了，这半年来的坚持，总算还是有些许收获。 希望自己不负青春，加油养成自律、坚定的好习惯。","link":"/2019/11/11/005-马拉松/"},{"title":"redis-cli的实现原理","text":"首先从源码中找入口redis源码：src/redis-cli.c中找到main函数，main函数中核心的处理就是以下部分 12345678910/* Start interactive mode when no command is provided */if (argc == 0 &amp;&amp; !config.eval) { /* Ignore SIGPIPE in interactive mode to force a reconnect */ signal(SIGPIPE, SIG_IGN); /* Note that in repl mode we don&apos;t abort on connection error. * A new attempt will be performed for every command send. */ cliConnect(0); repl();} cliConnect主要是与服务端建立连接，每一个连接都会创建一个redisContext结构来保存 replrepl实现了发送命令并输出Server返回结果的主要逻辑 RedisContextredisContext结构如下，重要的字段都进行了注释 12345678910111213141516171819202122typedef struct redisContext { int err; /* Error flags, 0 when there is no error */ char errstr[128]; /* String representation of error when applicable */ int fd; // socket句柄，用户连接redis server int flags; char *obuf; /* Write buffer */ //主要存储发送的命令，resp协议封装后的sds redisReader *reader; /* Protocol reader */ // 存储server返回的数据 enum redisConnectionType connection_type; struct timeval *timeout; struct { char *host; char *source_addr; int port; } tcp; struct { char *path; } unix_sock;} redisContext; repl是做什么的repl其实质就是在不停的重复解析用户输入的命令和redis server返回的参数。repl中，实现这个核心操作的便是issueCommandRepeat方法。 issueCommandRepeat方法我们直观来想，需要做3步操作 从标准输入获取用户输入的命令和参数，并按照resp协议封装 将封装后的数据发送至服务器 读取从服务器返回的结果并解析输出 cli如何封装输入的命令和参数通过对issueCommandRepeat方法的分析，极其对它里边调用关系的梳理，发现是redisAppendCommandArgv处理命令并将命令写入context的obuf中，redisAppendCommandArgv的调用层级和源码如下 12345678910111213141516171819202122232425issueCommandRepeat cliSendCommand redisAppendCommandArgv redisFormatSdsCommandArgv __redisAppendCommand源码： sds cmd; int len; //redisFormatSdsCommandArgv是将命令极其跟随的参数，使用resp协议封装后，存到一个sds结构中。 len = redisFormatSdsCommandArgv(&amp;cmd,argc,argv,argvlen); if (len == -1) { __redisSetError(c,REDIS_ERR_OOM,&quot;Out of memory&quot;); return REDIS_ERR; } //__redisAppendCommand是将sds保存的resp协议的数据存到redisContext中的obuf中 if (__redisAppendCommand(c,cmd,len) != REDIS_OK) { sdsfree(cmd); return REDIS_ERR; } // 释放sds结构申请的内存 sdsfree(cmd); return REDIS_OK; 向服务器发送命令有了封装好的数据，下一步就是可以向服务器发送命令了，还是issueCommandRepeat方法，看下述代码 1234567891011121314151617181920212223242526272829303132333435363738while(repeat-- &gt; 0) { redisAppendCommandArgv(context,argc,(const char**)argv,argvlen); while (config.monitor_mode) { if (cliReadReply(output_raw) != REDIS_OK) exit(1); fflush(stdout); } if (config.pubsub_mode) { if (config.output != OUTPUT_RAW) printf(&quot;Reading messages... (press Ctrl-C to quit)\\n&quot;); while (1) { if (cliReadReply(output_raw) != REDIS_OK) exit(1); } } if (config.slave_mode) { printf(&quot;Entering replica output mode... (press Ctrl-C to quit)\\n&quot;); slaveMode(); config.slave_mode = 0; zfree(argvlen); return REDIS_ERR; /* Error = slaveMode lost connection to master */ } if (cliReadReply(output_raw) != REDIS_OK) { zfree(argvlen); return REDIS_ERR; } else { /* Store database number when SELECT was successfully executed. */ if (!strcasecmp(command,&quot;select&quot;) &amp;&amp; argc == 2 &amp;&amp; config.last_cmd_type != REDIS_REPLY_ERROR) { config.dbnum = atoi(argv[1]); cliRefreshPrompt(); } else if (!strcasecmp(command,&quot;auth&quot;) &amp;&amp; argc == 2) { cliSelect(); } } if (config.interval) usleep(config.interval); fflush(stdout); /* Make it grep friendly */ } 我们知道redisAppendCommandArgv只是组装了命令，并没有发送，cliReadReply看样子是将结果读取，最后fflush是将结果输出到标准输出。那么发送命令只可能藏在cliReadReply中，继续分析cliReadyReply 12cliReadyReply redisGetReply 在redisGetReply中发现特别隐藏的redisBufferWrite，这个实际是发送了请求，我们看具体代码 1234567891011121314151617181920if (sdslen(c-&gt;obuf) &gt; 0) { // 发送命令 nwritten = write(c-&gt;fd,c-&gt;obuf,sdslen(c-&gt;obuf)); if (nwritten == -1) { if ((errno == EAGAIN &amp;&amp; !(c-&gt;flags &amp; REDIS_BLOCK)) || (errno == EINTR)) { /* Try again later */ } else { __redisSetError(c,REDIS_ERR_IO,NULL); return REDIS_ERR; } } else if (nwritten &gt; 0) { // 发送成功，清理obuf if (nwritten == (signed)sdslen(c-&gt;obuf)) { sdsfree(c-&gt;obuf); c-&gt;obuf = sdsempty(); } else { sdsrange(c-&gt;obuf,nwritten,-1); } }} 读取服务器返回的结果继续在redisGetReply读代码，能够看到redisBufferRead是获取服务器返回的数据的方法。 12345678910111213141516171819202122232425262728int redisBufferRead(redisContext *c) { char buf[1024*16]; int nread; /* Return early when the context has seen an error. */ if (c-&gt;err) return REDIS_ERR; // 从fd读取数据 nread = read(c-&gt;fd,buf,sizeof(buf)); if (nread == -1) { if ((errno == EAGAIN &amp;&amp; !(c-&gt;flags &amp; REDIS_BLOCK)) || (errno == EINTR)) { /* Try again later */ } else { __redisSetError(c,REDIS_ERR_IO,NULL); return REDIS_ERR; } } else if (nread == 0) { __redisSetError(c,REDIS_ERR_EOF,&quot;Server closed the connection&quot;); return REDIS_ERR; } else { if (redisReaderFeed(c-&gt;reader,buf,nread) != REDIS_OK) { __redisSetError(c,c-&gt;reader-&gt;err,c-&gt;reader-&gt;errstr); return REDIS_ERR; } } return REDIS_OK;} 从代码可以看到如果读取成功会调用redisReaderFeed将buf内容写入到redisContext中的reader里对应的buf中 redisGetReply中，又调用了redisGetReplyFromReader，redisReaderGetReply将返回的数据通过resp协议解析为字符串 1234567int redisGetReplyFromReader(redisContext *c, void **reply) { if (redisReaderGetReply(c-&gt;reader,reply) == REDIS_ERR) { __redisSetError(c,c-&gt;reader-&gt;err,c-&gt;reader-&gt;errstr); return REDIS_ERR; } return REDIS_OK;} 最终结果的输出最终结果的输出还是在cliReadReply中。将数据存储在字符串中，通过fwrite写入标准输出中，再返回到cliSendCommand中fflush后输出到终端","link":"/2019/11/29/006-redis-cli/"},{"title":"redis-server","text":"首先在initServer中，注册eventloop，为io复用做准备 12server.cserver.el = aeCreateEventLoop(server.maxclients+CONFIG_FDSET_INCR); ListenToPort创建基于tcp的socket连接，并监听客户端连接，并将该socket设置为非阻塞 12345server.c/* Open the TCP listening socket for the user commands. */if (server.port != 0 &amp;&amp; listenToPort(server.port,server.ipfd,&amp;server.ipfd_count) == C_ERR) exit(1); 为每个server的fd设置可读事件回调 12345for (j = 0; j &lt; server.ipfd_count; j++) { if (aeCreateFileEvent(server.el, server.ipfd[j], AE_READABLE, acceptTcpHandler,NULL) == AE_ERR) { serverPanic(&quot;Unrecoverable error creating server.ipfd file event.&quot;); }} aeCreateFileEvent 123456789101112131415161718192021222324252627282930313233343536ae.ctypedef struct aeFileEvent { int mask; /* one of AE_(READABLE|WRITABLE|BARRIER) */ aeFileProc *rfileProc; aeFileProc *wfileProc; void *clientData;} aeFileEvent;int aeCreateFileEvent(aeEventLoop *eventLoop, int fd, int mask, aeFileProc *proc, void *clientData){ if (fd &gt;= eventLoop-&gt;setsize) { errno = ERANGE; return AE_ERR; } // 获取对应server socket fd对应的event aeFileEvent *fe = &amp;eventLoop-&gt;events[fd]; // 把fd写入eventloop的state里 if (aeApiAddEvent(eventLoop, fd, mask) == -1) return AE_ERR; // 设置该fd对应event的读状态或写状态 fe-&gt;mask |= mask; // 注册读写处理的回调函数proc if (mask &amp; AE_READABLE) fe-&gt;rfileProc = proc; if (mask &amp; AE_WRITABLE) fe-&gt;wfileProc = proc; // 存储数据 fe-&gt;clientData = clientData; // 更新eventloop的最大fd if (fd &gt; eventLoop-&gt;maxfd) eventLoop-&gt;maxfd = fd; return AE_OK;} 再来看看acceptTcpHandler 1234567891011121314151617181920void acceptTcpHandler(aeEventLoop *el, int fd, void *privdata, int mask) { int cport, cfd, max = MAX_ACCEPTS_PER_CALL; char cip[NET_IP_STR_LEN]; UNUSED(el); UNUSED(mask); UNUSED(privdata); while(max--) { 对于每个server的fd，accept一个客户端fd，封装了普通的accept cfd = anetTcpAccept(server.neterr, fd, cip, sizeof(cip), &amp;cport); if (cfd == ANET_ERR) { if (errno != EWOULDBLOCK) serverLog(LL_WARNING, &quot;Accepting client connection: %s&quot;, server.neterr); return; } serverLog(LL_VERBOSE,&quot;Accepted %s:%d&quot;, cip, cport); acceptCommonHandler(connCreateAcceptedSocket(cfd),0,cip); }} acceptCommonHandler 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455static void acceptCommonHandler(connection *conn, int flags, char *ip) { client *c; UNUSED(ip); /* Admission control will happen before a client is created and connAccept() * called, because we don&apos;t want to even start transport-level negotiation * if rejected. */ if (listLength(server.clients) &gt;= server.maxclients) { char *err = &quot;-ERR max number of clients reached\\r\\n&quot;; /* That&apos;s a best effort error message, don&apos;t check write errors. * Note that for TLS connections, no handshake was done yet so nothing is written * and the connection will just drop. */ if (connWrite(conn,err,strlen(err)) == -1) { /* Nothing to do, Just to avoid the warning... */ } server.stat_rejected_conn++; connClose(conn); return; } /* Create connection and client */ // 创建客户端，设置该fd非阻塞，并且设置读函数readQueryFromClient if ((c = createClient(conn)) == NULL) { char conninfo[100]; serverLog(LL_WARNING, &quot;Error registering fd event for the new client: %s (conn: %s)&quot;, connGetLastError(conn), connGetInfo(conn, conninfo, sizeof(conninfo))); connClose(conn); /* May be already closed, just ignore errors */ return; } /* Last chance to keep flags */ c-&gt;flags |= flags; /* Initiate accept. * * Note that connAccept() is free to do two things here: * 1. Call clientAcceptHandler() immediately; * 2. Schedule a future call to clientAcceptHandler(). * * Because of that, we must do nothing else afterwards. */ if (connAccept(conn, clientAcceptHandler) == C_ERR) { char conninfo[100]; serverLog(LL_WARNING, &quot;Error accepting a client connection: %s (conn: %s)&quot;, connGetLastError(conn), connGetInfo(conn, conninfo, sizeof(conninfo))); freeClient(connGetPrivateData(conn)); return; }} redis的eventloop在哪 -&gt; aeMain`","link":"/2020/02/19/008-redis-server/"},{"title":"Git 配置","text":"经常使用公司的git仓库，同时也需要使用github，此时git的配置就会出问题。由于git配置的用户名和密码均是全局的，会导致如果使用github的配置如果不指定，就按照公司的git配置中的默认用户名提交。 解决办法，在github仓库中设置local配置 12git config --local user.name xxxgit config --local user.email xxx@xxx.com","link":"/2020/04/26/010-git/"},{"title":"IO复用之epoll","text":"IO复用select、poll和epoll是三个常用的IO多路复用方法，具体的差别和性能从左到右都是有区别的。但对于这几种IO复用方法是如何使用的，还是一知半解。 实例这几天，通过阅读redis的源码，对epoll的使用方法有了进一步的认识。因此，这里使用epoll做一个简单的接受io请求的例子 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071#include &lt;stdio.h&gt;#include &lt;sys/socket.h&gt;#include &lt;arpa/inet.h&gt;#include &lt;sys/epoll.h&gt;#include &lt;sys/types.h&gt;#include &lt;sys/socket.h&gt;#include &lt;sys/stat.h&gt;#include &lt;sys/un.h&gt;#include &lt;sys/time.h&gt;#include &lt;netinet/in.h&gt;#include &lt;netinet/tcp.h&gt;#include &lt;fcntl.h&gt;#include &lt;stdlib.h&gt;#include &lt;unistd.h&gt;server.cint main(int argc , char *argv[]){ int epfd, sfd, new_socket, c, count; struct sockaddr_in server, client; struct epoll_event *events; struct epoll_event ee = {0}; events = (struct epoll_event*)malloc(sizeof(struct epoll_event)*100); //Create socket sfd = socket(AF_INET , SOCK_STREAM , 0); if (sfd == -1) { printf(&quot;Could not create socket&quot;); } server.sin_family = AF_INET; server.sin_addr.s_addr = INADDR_ANY; server.sin_port = htons( 9886); //Bind if( bind(socket_desc, (struct sockaddr *)&amp;server , sizeof(server))) { printf(&quot;failed to bind&quot;); } //Listen listen(sfd, 3); // 设置非阻塞 if (fcntl(socket_desc, F_SETFL, O_NONBLOCK) == -1) { printf(&quot;set non block faild&quot;); } //创建epoll epfd = epoll_create(1024); if (epfd == -1) { printf(&quot;epoll create failed&quot;); } // 为sfd，监听读io ee.events |= EPOLLIN; if (epoll_ctl(epfd, EPOLL_CTL_ADD, sfd, &amp;ee) == -1) { printf(&quot;register failed&quot;); } while(1) { count = epoll_wait(epfd, events, 100,0); if (count &gt; 0) { // 这里其实已经定位到有监听的fd，读io已经就绪，根据count遍历events列表，便可得到实际消息和对应的处理方法 printf(&quot;mo god&quot;); break; } } return 0;} 123456789101112131415161718192021222324252627282930313233343536373839404142client.cint main(int argc, char** argv){ int sockfd, n,rec_len; char recvline[4096], sendline[4096]; char buf[MAXLINE]; char *addr = &quot;127.0.0.1&quot;; struct sockaddr_in servaddr; if( (sockfd = socket(AF_INET, SOCK_STREAM, 0)) &lt; 0){ printf(&quot;create socket error: %s(errno: %d)\\n&quot;, strerror(errno),errno); exit(0); } memset(&amp;servaddr, 0, sizeof(servaddr)); servaddr.sin_family = AF_INET; servaddr.sin_port = htons(9886); if( inet_pton(AF_INET, addr, &amp;servaddr.sin_addr) &lt;= 0){ //inet_pton是Linux下IP地址转换函数，将IP地址在“点分十进制”和“整数”之间转换 printf(&quot;inet_pton error for %s\\n&quot;,argv[1]); exit(0); } if( connect(sockfd, (struct sockaddr*)&amp;servaddr, sizeof(servaddr)) &lt; 0){ printf(&quot;connect error: %s(errno: %d)\\n&quot;,strerror(errno),errno); exit(0); } printf(&quot;send msg to server: \\n&quot;); fgets(sendline, 4096, stdin); if( send(sockfd, sendline, strlen(sendline), 0) &lt; 0) { printf(&quot;send msg error: %s(errno: %d)\\n&quot;, strerror(errno), errno); exit(0); } if((rec_len = recv(sockfd, buf, MAXLINE,0)) == -1) { perror(&quot;recv error&quot;); exit(1); } buf[rec_len] = &apos;\\0&apos;; printf(&quot;Received : %s &quot;,buf); close(sockfd); exit(0);}","link":"/2020/02/24/009-epoll/"},{"title":"Spark基础学习","text":"RDDRDD的4大属性 partitions: 数据分片 partitioner: 分片切割原则 dependencies: RDD依赖 compute: 转换函数 实例 如果把“带泥土豆”看成是 RDD 的话，那么 RDD 的 partitions 属性，囊括的正是麻袋里那一颗颗脏兮兮的土豆。同理，流水线上所有洗净的土豆，一同构成了“干净土豆”RDD的partitions 属性。 我们再来看RDD的partitioner 属性，这个属性定义了把原始数据集切割成数据分片的切割规则。在土豆工坊的例子中，“带泥土豆”RDD 的切割规则是随机拿取，也就是从麻袋中随机拿取一颗脏兮兮的土豆放到流水线上。后面的食材形态，如“干净豆”、“土豆片”和“即食薯片”，则沿用了“带泥土豆”RDD 的切割规则。换句话说，后续的这些RDD，分别继承了前一个 RDD 的 partitioner 属性。 这里面与众不同的是“分发的即食薯片”。显然，“分发的即食薯片”是通过对“即食薯片”按照大、中、小号做分发得到的。也就是说，对于“分发的即食薯片”来说，它的partitioner 属性，重新定义了这个 RDD 数据分片的切割规则，也就是把先前 RDD 的数据分片打散，按照薯片尺寸重新构建数据分片。 由这个例子我们可以看出，数据分片的分布，是由 RDD 的 partitioner 决定的。因此，RDD 的 partitions 属性，与它的 partitioner 属性是强相关的。 依赖和转换在数据形态的转换过程中，每个 RDD 都会通过 dependencies 属性来记录它所依赖的前一个、或是多个 RDD，简称“父 RDD”。与此同时，RDD 使用 compute 属性，来记录从父 RDD 到当前 RDD 的转换操作。 拿 Word Count 当中的 wordRDD 来举例，它的父 RDD 是 lineRDD，因此，它的dependencies 属性记录的是 lineRDD。从 lineRDD 到 wordRDD 的转换，其所依赖的操作是 flatMap，因此，wordRDD 的 compute 属性，记录的是 flatMap 这个转换函数。 总结总结下来，薯片的加工流程，与RDD的概念和4大属性是一一对应的 不同的食材形态，如带泥土豆、土豆片、即食薯片等等，对应的就是RDD概念； 同一种食材形态在不同流水线上的具体实物，就是RDD的partitions属性； 食材按照什么规则被分配到哪条流水线，对应的就是RDD的partitioner属性； 每一种食材形态都会依赖上一种形态，这种依赖关系对应的是RDD中的dependencies 属性； 不同环节的加工方法对应RDD的compute属性。 编程模型和延迟计算RDD代表的是分布式数据形态，因此，RDD到RDD之间的转换，本质上是数据形态上的转换（Transformations）。在RDD的编程模型中，一共有两种算子，Transformations 类算子和 Actions 类算子。开发者需要使用 Transformations 类算子，定义并描述数据形态的转换过程，然后调用Actions类算子，将计算结果收集起来、或是物化到磁盘。 在这样的编程模型下，Spark 在运行时的计算被划分为两个环节。 基于不用数据形态之间的转换，构建计算流图（DAG，Directed Acyclic Graph）； 通过Actions类算子，以回溯的方式去触发执行这个计算流图。 开发者调用的各类 Transformations 算子，并不立即执行计算，当且仅当开发者调用Actions算子时，之前调用的转换算子才会付诸执行。在业内，这样的计算模式有个专门的术语，叫作“延迟计算”（Lazy Evaluation） ? 什么是Transformations算子，什么是Actions类算子，需要去查","link":"/2022/12/23/013-spark/"},{"title":"Redis cli处理服务端的返回逻辑","text":"redisGetReply方法 redisGetReply 中的 redisBufferRead 的作用是将数据读取到 redis context 的 reader 中，每个 reader 都包含一个读 buf，pos 和 len 记录了 buf 的长度和读取位置 12345678910111213141516typedef struct redisReader { int err; /* Error flags, 0 when there is no error */ char errstr[128]; /* String representation of error when applicable */ char *buf; /* Read buffer */ size_t pos; /* Buffer cursor */ size_t len; /* Buffer length */ size_t maxbuf; /* Max length of unused buffer */ redisReadTask rstack[9]; // 遍历使用的栈 int ridx; /* Index of current read task */ 标识遍历到哪一层 void *reply; /* Temporary reply pointer */ redisReplyObjectFunctions *fn; void *privdata;} redisReader; buf：读缓冲区 pos：当前读取到的位置 len：buff 的长度 redisReaderGetReply redisReaderGetReply是将reader中保存的数据生成一个reply 1234567891011121314151617181920212223先来看用到的数据结构typedef struct redisReadTask { int type; int elements; /* number of elements in multibulk container */ int idx; /* index in parent (array) object */ void *obj; /* holds user-generated value for a read task */ struct redisReadTask *parent; /* parent task */ void *privdata; /* user-settable arbitrary field */} redisReadTask;/* This is the reply object returned by redisCommand() */typedef struct redisReply { int type; /* REDIS_REPLY_* */ long long integer; /* The integer when type is REDIS_REPLY_INTEGER */ double dval; /* The double when type is REDIS_REPLY_DOUBLE */ size_t len; /* Length of string */ char *str; /* Used for REDIS_REPLY_ERROR, REDIS_REPLY_STRING and REDIS_REPLY_DOUBLE (in additionl to dval). */ char vtype[4]; /* Used for REDIS_REPLY_VERB, contains the null terminated 3 character content type, such as &quot;txt&quot;. */ size_t elements; /* number of elements, for REDIS_REPLY_ARRAY */ struct redisReply **element; /* elements vector for REDIS_REPLY_ARRAY */} 处理流程 redisReaderGetReply中初始化栈，生成根节点，如下所示 123456789if (r-&gt;ridx == -1) { r-&gt;rstack[0].type = -1; r-&gt;rstack[0].elements = -1; r-&gt;rstack[0].idx = -1; r-&gt;rstack[0].obj = NULL; r-&gt;rstack[0].parent = NULL; r-&gt;rstack[0].privdata = r-&gt;privdata; r-&gt;ridx = 0;} 深度优先遍历所有节点 123while (r-&gt;ridx &gt;= 0) if (processItem(r) != REDIS_OK) break; 返回reply给上层方法 123456789/* Emit a reply when there is one. */if (r-&gt;ridx == -1) { if (reply != NULL) { *reply = r-&gt;reply; } else if (r-&gt;reply != NULL &amp;&amp; r-&gt;fn &amp;&amp; r-&gt;fn-&gt;freeObject) { r-&gt;fn-&gt;freeObject(r-&gt;reply); } r-&gt;reply = NULL;} 关键的processItemprocessItem中对resp协议的每一种元素进行了识别，同时将这些类型划分为三类，分别是：processLineItem、processBulkItem、processAggregateItem。通过以下代码可方便的看出这三种分别对应的数据类型 123456789101112131415switch(cur-&gt;type) { case REDIS_REPLY_ERROR: case REDIS_REPLY_STATUS: case REDIS_REPLY_INTEGER: case REDIS_REPLY_DOUBLE: case REDIS_REPLY_NIL: case REDIS_REPLY_BOOL: return processLineItem(r); case REDIS_REPLY_STRING: case REDIS_REPLY_VERB: return processBulkItem(r); case REDIS_REPLY_ARRAY: case REDIS_REPLY_MAP: case REDIS_REPLY_SET: return processAggregateItem(r); processAggregateItemprocessAggregateItem也算直观，如果elements &gt; 0，则将该task节点信息完善，完成该节点对应的reply的obj赋值。同时创建一个新的task，为了进一步的遍历后续节点 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677static int processAggregateItem(redisReader *r) { redisReadTask *cur = &amp;(r-&gt;rstack[r-&gt;ridx]); void *obj; char *p; long long elements; int root = 0, len; /* Set error for nested multi bulks with depth &gt; 7 */ if (r-&gt;ridx == 8) { __redisReaderSetError(r,REDIS_ERR_PROTOCOL, &quot;No support for nested multi bulk replies with depth &gt; 7&quot;); return REDIS_ERR; } if ((p = readLine(r,&amp;len)) != NULL) { if (string2ll(p, len, &amp;elements) == REDIS_ERR) { __redisReaderSetError(r,REDIS_ERR_PROTOCOL, &quot;Bad multi-bulk length&quot;); return REDIS_ERR; } root = (r-&gt;ridx == 0); if (elements &lt; -1 || (LLONG_MAX &gt; SIZE_MAX &amp;&amp; elements &gt; SIZE_MAX)) { __redisReaderSetError(r,REDIS_ERR_PROTOCOL, &quot;Multi-bulk length out of range&quot;); return REDIS_ERR; } if (elements == -1) { if (r-&gt;fn &amp;&amp; r-&gt;fn-&gt;createNil) obj = r-&gt;fn-&gt;createNil(cur); else obj = (void*)REDIS_REPLY_NIL; if (obj == NULL) { __redisReaderSetErrorOOM(r); return REDIS_ERR; } moveToNextTask(r); } else { if (cur-&gt;type == REDIS_REPLY_MAP) elements *= 2; if (r-&gt;fn &amp;&amp; r-&gt;fn-&gt;createArray) obj = r-&gt;fn-&gt;createArray(cur,elements); else obj = (void*)(long)cur-&gt;type; if (obj == NULL) { __redisReaderSetErrorOOM(r); return REDIS_ERR; } /* Modify task stack when there are more than 0 elements.*/ if (elements &gt; 0) { cur-&gt;elements = elements; cur-&gt;obj = obj; r-&gt;ridx++; r-&gt;rstack[r-&gt;ridx].type = -1; r-&gt;rstack[r-&gt;ridx].elements = -1; r-&gt;rstack[r-&gt;ridx].idx = 0; r-&gt;rstack[r-&gt;ridx].obj = NULL; r-&gt;rstack[r-&gt;ridx].parent = cur; r-&gt;rstack[r-&gt;ridx].privdata = r-&gt;privdata; } else { moveToNextTask(r); } } /* Set reply if this is the root object. */ if (root) r-&gt;reply = obj; return REDIS_OK; } return REDIS_ERR;} processLineItemprocessLineItem比较奇怪，因为创建了obj后一直没有使用它。但是有个细节，我们看下：obj = r-&gt;fn-&gt;createInteger(cur,v)。这说明基于v值创建的对象其实已经绑定到了cur任务中。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081static int processLineItem(redisReader *r) { redisReadTask *cur = &amp;(r-&gt;rstack[r-&gt;ridx]); void *obj; char *p; int len; if ((p = readLine(r,&amp;len)) != NULL) { if (cur-&gt;type == REDIS_REPLY_INTEGER) { if (r-&gt;fn &amp;&amp; r-&gt;fn-&gt;createInteger) { long long v; if (string2ll(p, len, &amp;v) == REDIS_ERR) { __redisReaderSetError(r,REDIS_ERR_PROTOCOL, &quot;Bad integer value&quot;); return REDIS_ERR; } obj = r-&gt;fn-&gt;createInteger(cur,v); } else { obj = (void*)REDIS_REPLY_INTEGER; } } else if (cur-&gt;type == REDIS_REPLY_DOUBLE) { if (r-&gt;fn &amp;&amp; r-&gt;fn-&gt;createDouble) { char buf[326], *eptr; double d; if ((size_t)len &gt;= sizeof(buf)) { __redisReaderSetError(r,REDIS_ERR_PROTOCOL, &quot;Double value is too large&quot;); return REDIS_ERR; } memcpy(buf,p,len); buf[len] = &apos;\\0&apos;; if (strcasecmp(buf,&quot;,inf&quot;) == 0) { d = INFINITY; /* Positive infinite. */ } else if (strcasecmp(buf,&quot;,-inf&quot;) == 0) { d = -INFINITY; /* Nevative infinite. */ } else { d = strtod((char*)buf,&amp;eptr); if (buf[0] == &apos;\\0&apos; || eptr[0] != &apos;\\0&apos; || isnan(d)) { __redisReaderSetError(r,REDIS_ERR_PROTOCOL, &quot;Bad double value&quot;); return REDIS_ERR; } } obj = r-&gt;fn-&gt;createDouble(cur,d,buf,len); } else { obj = (void*)REDIS_REPLY_DOUBLE; } } else if (cur-&gt;type == REDIS_REPLY_NIL) { if (r-&gt;fn &amp;&amp; r-&gt;fn-&gt;createNil) obj = r-&gt;fn-&gt;createNil(cur); else obj = (void*)REDIS_REPLY_NIL; } else if (cur-&gt;type == REDIS_REPLY_BOOL) { int bval = p[0] == &apos;t&apos; || p[0] == &apos;T&apos;; if (r-&gt;fn &amp;&amp; r-&gt;fn-&gt;createBool) obj = r-&gt;fn-&gt;createBool(cur,bval); else obj = (void*)REDIS_REPLY_BOOL; } else { /* Type will be error or status. */ if (r-&gt;fn &amp;&amp; r-&gt;fn-&gt;createString) obj = r-&gt;fn-&gt;createString(cur,p,len); else obj = (void*)(size_t)(cur-&gt;type); } if (obj == NULL) { __redisReaderSetErrorOOM(r); return REDIS_ERR; } /* Set reply if this is the root object. */ if (r-&gt;ridx == 0) r-&gt;reply = obj; moveToNextTask(r); return REDIS_OK; } return REDIS_ERR;} 具体来看下createInteger，发现如果父节点是map、array、set，则将数据放入父节点对象的elements中，如果非结构化对象，则直接返回整数对象，其余line类型的数据也类似。 123456789101112131415161718static void *createIntegerObject(const redisReadTask *task, long long value) { redisReply *r, *parent; r = createReplyObject(REDIS_REPLY_INTEGER); if (r == NULL) return NULL; r-&gt;integer = value; if (task-&gt;parent) { // 如果父节点是map、array、set，则将数据放入父节点对象的elements中 parent = task-&gt;parent-&gt;obj; assert(parent-&gt;type == REDIS_REPLY_ARRAY || parent-&gt;type == REDIS_REPLY_MAP || parent-&gt;type == REDIS_REPLY_SET); parent-&gt;element[task-&gt;idx] = r; } return r;}","link":"/2020/01/07/007-Redis-get-reply/"},{"title":"Mysql Innodb引擎中的锁","text":"本文参考Mysql官方文档 共享锁和排它锁 共享锁（shared locks：s lock） 排它锁（exclusive locks：x lock） 意向锁（intention locks）- 表级别 共享意向锁（intention shared lock -&gt; IS） 排他意向锁（intention exclusive lock -&gt; IX） 意向锁与行锁间的关系 X IX S IS X Conflict Conflict Conflict Conflict IX Conflict Compatible Conflict Conflict S Conflict Conflict Compatible Compatible IS Conflict Compatible Compatible Compatible 意向锁注意事项 事务申请一个表中某行记录的共享锁前，必须申请该表的IS lock或更强的锁 事务申请一个表中某行记录的排他锁前，必须申请该表的IX lock 意向锁只阻塞表级别的加锁请求（for example, LOCK TABLES ... WRITE)。意图锁主要是为了表明某些客户端正在或将要锁住表中的某一行。 记录锁(record lock)记录锁也叫做行锁，是用来在一条索引记录上加锁来实现。例如SELECT c1 FROM t WHERE c1 = 10 FOR UPDATE; 会阻止其他事务插入、更新或删除t.c1值为10的数据行。 记录锁通常通过锁住索引记录来实现，即便一个mysql的table没有定义索引，在这种情况下InnoDB会创建一个隐藏的索引来用该索引来加记录锁。See Section 15.6.2.1, “Clustered and Secondary Indexes”. 间隙锁间隙锁是一个锁定索引记录间隙的锁，或者是一个可锁住第一条记录之前或者最后一条记录之后的锁。它只锁间隙，并不所具体的数据行。 例如, SELECT c1 FROM t WHERE c1 BETWEEN 10 and 20 FOR UPDATE; 阻止其他事务插入一个 t.c1的值为15的记录，无论是否已经存在列为15的记录, 因为15到20间的间隙已经被锁。 间隙锁不作用于unique索引的记录，对于unique索引，间隙锁只是锁住了这行数据，并不锁对应的间隙。如sql: SELECT * FROM child WHERE id = 100;，只锁定id=100的行记录。如果id所在列没有索引记录或者是一个非唯一索引，那这条语句可以锁住语句的间隙。 需要注意的是，InnoDB中的间隙锁的目的只是为了阻止其他事务在间隙中插入数据，事务间的间隙锁是可以共存的，对于一个事务A在间隙(m, n)上获取间隙锁，并不影响事务B在同样的间隙(m, n)上获取间隙锁。对于共享和排他的间隙锁都是如此，没有差别。 探索索引为unique key时的间隙锁 首先我们来建一张表，并给表中插入一部分数据： 12345678910111213141516171819202122CREATE TABLE `demo` ( `id` int(11) NOT NULL, `number` int(11) NOT NULL DEFAULT &apos;0&apos;, PRIMARY KEY (`id`), KEY `number` (`number`)) ENGINE=InnoDB DEFAULT CHARSET=utf8mysql&gt; select * from demo; +----+--------+| id | number |+----+--------+| 20 | 0 || 30 | 0 || 1 | 1 || 10 | 1 || 2 | 3 || 3 | 3 || 8 | 3 || 18 | 3 || 21 | 4 |+----+--------+9 rows in set (0.01 sec) 事务1 : select不存在的数据；事务2：插入数据。我们可以看到事务2 被阻塞 12345mysql&gt; begin;Query OK, 0 rows affected (0.01 sec)mysql&gt; select * from demo where id = 4 for update;Empty set (0.01 sec) 12345mysql&gt; begin;Query OK, 0 rows affected (0.01 sec)mysql&gt; insert into demo values (5,2);ERROR 1205 (HY000): Lock wait timeout exceeded; try restarting transaction 事务1 : select存在的数据；事务2：插入数据。我们可以看到事务2并没有被阻塞，同时也插入了对应的数据。 12345678910mysql&gt; begin;Query OK, 0 rows affected (0.00 sec)mysql&gt; select * from demo where id = 18 for update;+----+--------+| id | number |+----+--------+| 18 | 3 |+----+--------+1 row in set (0.00 sec) 12345mysql&gt; begin;Query OK, 0 rows affected (0.00 sec)mysql&gt; insert into demo values (19,2);Query OK, 1 row affected (0.00 sec) 非unique key索引情况下的 gap lock 还是同样的表，采用number列来做展示 12345678910111213141516mysql&gt; select * from demo;+----+--------+| id | number |+----+--------+| 20 | 0 || 1 | 1 || 19 | 2 || 8 | 3 || 2 | 5 || 3 | 8 || 10 | 9 || 30 | 12 || 18 | 15 || 21 | 20 |+----+--------+10 rows in set (0.00 sec) 事务1：查询已有数据；事务2：插入数据 12345678910mysql&gt; begin;Query OK, 0 rows affected (0.00 sec)mysql&gt; select * from demo where number = 15 for update; // 锁住(12, 20)范围内的间隙+----+--------+| id | number |+----+--------+| 18 | 15 |+----+--------+1 row in set (0.00 sec) 1234567mysql&gt; begin;Query OK, 0 rows affected (0.01 sec)// 插入number = 13的记录到间隙内，导致事务2阻塞// 因为事务2如果插入number=15的记录，会导致事务1产生幻读，因此为了避免该操作，只能锁住(12, 20)的间隙，这样插入number=13也会阻塞mysql&gt; insert into demo values (24, 13);ERROR 1205 (HY000): Lock wait timeout exceeded; try restarting transaction 事务1：查询已有数据；事务2：插入数据 1234567transaction 1mysql&gt; begin;Query OK, 0 rows affected (0.01 sec)//number = 17记录不存在，同样锁住(15, 20)区间mysql&gt; select * from demo where number = 17 for update; Empty set (0.00 sec) 12345678910111213mysql&gt; begin;Query OK, 0 rows affected (0.01 sec)// 插入number = 18的记录到间隙内，导致事务2阻塞// 因为事务2如果插入number=17的记录，会导致事务1产生幻读（第二次查突然有了数据），因此为了避免该操作，只能锁住(12, 20)的间隙，这便导致number=18的数据也无法插入mysql&gt; insert into demo values (29, 18);ERROR 1205 (HY000): Lock wait timeout exceeded; try restarting transaction// number = 12 和 number = 20 的记录可以插入，证明间隙锁是一锁一个开区间的间隙mysql&gt; insert into demo values (29, 20);Query OK, 1 row affected (0.01 sec)mysql&gt; insert into demo values (39, 12);Query OK, 1 row affected (0.00 sec) 间隙锁总结思考 唯一索引下的情况 记录存在：等同于行锁，因为记录为唯一索引，锁着该行，其他事务无法进行插入和修改 记录不存在：加锁范围为该记录上下界开区间，因为mysql不允许其他事务在该间隙内部插入新的数据或修改数据以便将值更新到该间隙区间，导致此事务内部产生幻读 非唯一索引下的情况：记录无论是否存在都会对间隙加锁，防止其他事务在修改数据更新到间隙内导致幻读 临键锁简单来讲临建锁 = 行锁 + 记录前的间隙锁，间隙锁是一个左开右闭的区间，假设一张表包含了10、11、13和20这几个数据，那么可以分割的间隙有 12345(negative infinity, 10](10, 11](11，13](13，20](20，正无穷) 假如有SQL语句SELECT * FROM table WHERE value = 13 FOR UPDATE;，根据临建锁的定义，锁住了(11，13]的区间，但实际上(13, 20)的间隙也会被锁住，因此实际要锁住的区间为(10, 20)","link":"/2020/08/31/011-innodblock/"},{"title":"Go的一些知识","text":"好文收藏 揭秘！Go Mod","link":"/2021/09/09/012-go_base/"}],"tags":[{"name":"nginx","slug":"nginx","link":"/tags/nginx/"},{"name":"life","slug":"life","link":"/tags/life/"},{"name":"run","slug":"run","link":"/tags/run/"},{"name":"redis","slug":"redis","link":"/tags/redis/"},{"name":"git","slug":"git","link":"/tags/git/"},{"name":"IO复用","slug":"IO复用","link":"/tags/IO复用/"},{"name":"大数据","slug":"大数据","link":"/tags/大数据/"},{"name":"mysql","slug":"mysql","link":"/tags/mysql/"},{"name":"Golang","slug":"Golang","link":"/tags/Golang/"}],"categories":[{"name":"技术研究","slug":"技术研究","link":"/categories/技术研究/"}]}